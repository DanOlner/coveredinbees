---
title: "Prototyping open econ tools"
date: "2025-09-04"
categories: [econ]
---


Over the past couple of years, I've been building up a loose 'regional economics' toolkit while digging into UK sectors, growth and other data (working mainly with [SYMCA](https://www.southyorkshire-ca.gov.uk/) wearing my [Y-PERN](https://y-pern.org.uk/) hat)[^githublink].

Over the next six months or so, I want to try and make this a more focused project. The plan is roughly this:

* Using open data/methods, test and improve these tools so they're as useful as they can be.
* Dig deeper into the ideas and questions we're pursuing - iterate between these and the tools.
* Build on existing relationships and make new ones to prototype a better tools/ideas/questions cycle.
* Help build capacity through things like [this ONS Local session](https://vimeo.com/user99857619/review/1103090076/32e50123d2) I ran introducing R for regional economic analysis ([the online slides here](https://danolner.github.io/RegionalEconomicTools/R_regecon_taster_2025_revealjs.html#/title-slide) work as a how-to guide, including how to use R easily in a browser).

Data/code/explanations are slowly being gathered into a [regecontools website](https://danolner.github.io/RegionalEconomicTools/), though bits are spread all over (this [live outputs page](https://danolner.github.io/posts/outputs_livelist/) on the techie blog has gathered most of it in one place). By building pipelines like this, we can speed up reports, maps, dashboards etc, and share them easily (that last link collects a bunch of these in one place). 

The least tested part of this for me, and maybe the most interesting, is the 'tools/ideas/questions' cycle. The tools/concepts we use to make sense of our regional economies have grown from a hodgepodge of ideas. These can be questioned at different levels - from narrowly methodological ("how much difference does it make to productivity if we exclude imputed rent? Do existing measures of public sector output capture their real value?") to deeper, more political ideas about what economies are and what/who they're for (see e.g. the [latest doughnut econs Nature paper](https://www.nature.com/articles/s41586-025-09385-1) or [this survey](https://www.sciencedirect.com/science/article/pii/S1470160X25010088?via%3Dihub#b0125) of over 200 eco-econs/wellbeing indicators).

Y-PERN's whole purpose has been to experiment with breaking down barriers in this cycle - trying to push past [deficit model](https://en.wikipedia.org/wiki/Information_deficit_model) thinking that just sees the cycle as a “transfer of information from experts to non-experts”. This is still a pretty entrenched view: academics toil in the dark for years, emerge pale and blinking, clutching new insights. A separate 'knowledge exchange' process then occurs.

But that doesn't align with the reality of data-driven policymaking: *everyone involved* are experts in what they do. It's a deeply collaborative endeavour. We don’t all share the same knowledge, but we also won’t progress much without bringing everyone’s together.

The 'open' part of the toolkit is in symbiosis with the 'ideas/questions' part. Regions face many of the same economic questions, including identical asks from central government (e.g. to produce Local Growth Plans). The same data sources are re-used, the same assumptions. At the same time, we're all working to develop our own identities as devolution deepens. Given that - 

> Do data work openly where we can. It will support collaboration and learning. It will help build a shared sense of ground truth. It will avoid wheel reinvention.

I don’t have a dogmatic fealty to open source — we need a data/analysis mixed economy where private providers can do things other can’t. There are also essential datasets that can't be open, for good reason. But *where we can*, working in the open just goes better with the grain of those three things: (1) collaborative learning/capacity building across silos; (2) developing our shared sense of ground truth; (3) avoiding wheel reinvention (a facet of [reproducibility](https://www.ukrn.org/), which needs open methods; you can’t reproduce something if you can’t access it).

The only way this works is if we prototype. Or call that [test and learn](https://www.bi.team/publications/test-and-learn-a-playbook-for-mission-driven-government/) if you prefer. As that doc says:

> At its simplest [it] involves (1) developing something; (2) making contact with reality; (3) learning from the results.

Sounds great in principle - but we have to be open to preconceptions being challenged when we smack into reality. The [Valve Games employee manual](https://cdn.fastly.steamstatic.com/apps/valve/Valve_NewEmployeeHandbook.pdf)[^valvenope] puts it like this:

> “-----ing up is a great way to find out that your assumptions were wrong or that your model of the world was a little bit off. As long as you update your model and move forward with a better picture, you’re doing it right. Look for ways to test your beliefs. Never be afraid to run an experiment or to collect more data.”

While not always comfortable, this is part of how to grow our shared sense of ground truth. It's perfect '[blind people and elephant](https://en.wikipedia.org/wiki/Blind_men_and_an_elephant)' parable territory[^econelephant]. Brace for an extremely mixed elephant/economy metaphor.

* We want to see as much of the elephant as we can. How is the economy structured, what's growing, shrinking, changing? Why? 
* Those lead naturally to “What data/methods do we have to answer them?” Any one data source helps us grab a single pachiderm part. Multiple sources give us a grip on different bits, but the whole beast still eludes us. We need enough knowledge to know our tools' limitations - we will regularly hit the [streetlight effect](https://en.wikipedia.org/wiki/Streetlight_effect), mistaking the data for the whole animal[^krug].

Combining openness and prototyping, though, we can exchange what we think we've seen with others, maybe learn from our errors, and move a step or two closer to a collective sense of the shape.

Then there are awkward people saying things like, "Are we *sure* this is an elephant? I think maybe we have to go back to first principles here." But again - an open, testing approach lets us argue our competing pachiderm theories out, and often discover diverse tools can be used in different places very effectively despite no total agreement.

Coming back to the aims - these will necessarily have to be fairly narrow to achieve anything at all. I'll most likely start by testing some different basic ONS and Companies house economy measures, see what could be improved, what blind spots are. I'll also try to find two or three focused problems to apply this to - including, I'm hoping, something on how we close the gap between quant views of sector mix and ground level knowledge of how firms interact and what difference that makes to their success.

Let's see how contact with reality changes things...

[^githublink]: [Github file history](https://github.com/DanOlner/coveredinbees/commits/87fa6e586e9ff7bb64d735d4e36c08d006f171bd/posts/open_econtools/index.qmd) for previous drafts / cuttings.
[^econelephant]: Elephant parable [example](https://jetzek.wordpress.com/2016/07/19/first-blog-post/) applied to economics. 
[^krug]: Krugman: "We just don't see what we can't formalise". [citation forgotten!]
[^valvenope]: Not an endorsement of Valve's supposedly desk-on-wheels culture or anything similar. As [this article explores](https://www.theguardian.com/commentisfree/2018/jul/30/no-bosses-managers-flat-hierachy-workplace-tech-hollywood), structures like this (including some co-ops without explicit rules) can mask a "neo-feudal workplace culture".




## CUTTINZ

Not deny reality of austerity-hit LAs lack of bodies
but can we move a few more notches to breaking down distinctions in the networks we make, getting past institutional diffs?

Experience has shown doing that has to start with people - those willing to work together on the same problems... 

It wouldn't be possible or wise to try and do all things econ-toolkit-wise (see e.g. this synthesis of inclusive econ measures; there are so many!)


Prototyping what this niche is
What specific qualities these kinds of networks can bring and why they flow naturally from / are a good match for the direction of devolution

That last one covers both normative stuff and 'theory of data / theory of change' stuff.




But this is one of the things I want to experiment with. It's a good time to try 

because of the networks because of being able to create space for it
Start with some humility - the world doesn't have a shortage of people who'll be willing to tell you they know The Answers.

Black box vs network [can mention some of the hollowing-out issues here that have no quick fix cf. Bradford community data]

What I think we have a chance to do collectively is a bit different - to create a shared sense of ground truth as we work together, built on the best understanding we can create between us.

(Also, these last two points are rarely so cleanly separated - back to that in a moment.)

Issues around avoiding data-driven questions, streetlight effect. Issue of developing our own internal model - not just infographic cf. x-ray
What are we missing? What’s wrong with our data and methods?

The limitations here include: “you need to leave the house and talk to people.” This is the quant data / reality gap...

Then, somewhere in here: what do we want? That’s the normative stuff. Try to unpick examples here. E.g. assumptions around how to make everyone more wealthy are key there, right?




But open methods are more aligned with what I think is the reality of data-driven policymaking: everyone involved are experts in what they do. This is a deeply collaborative endeavour. We don’t all have the same knowledge, but we also won’t progress much without bringing everyone’s together. Contrast to the [deficit model](https://en.wikipedia.org/wiki/Information_deficit_model), which imagines a “transfer of information from experts to non-experts”. (This is a fairly common view of e.g. the university / policy relationship.) 

Sometimes there’s straightforward transmission - if I’m teaching R coding methods to people who are new to it, say. But it’s never just that. I’ve seen this again and again in different settings - [here](https://www.danolner.net/2019/02/sheffields-first-data-for-good-hack-day), we bought some data skills but had little insight into what that Sheffield homelessness charity’s data actually meant. They made it make sense.

In regional policy, it’s been a little different but with the same outcome. 

Two things, the above then also capacity building / why open methods = learning/collab = capacity building (I think)

You probably wouldn’t want collaborative heart surgery for example

Because it’s open, anyone can contribute, copy, re-use etc


So the more we build relationships and share tools and ideas, the better. Y-PERN's helped grow the strength of those relationships in Yorkshire & Humber

A lot of that groundwork has been done already through regional network building. We have a decent chance of getting a handle on a good two-thirds to three-quarters of the pachiderm.


The status of those last question types is tricky. As SYMCA's Alice Rubbra eloquently explains [here](https://y-pern.org.uk/blog/the-relationship-between-policymaking-and-research-how-it-works-sometimes/) on the Y-PERN blog, it's a clash of wotsits



Remain tool agnostic, code, no-code. I'm an R person, others won't be, and there are up and downsides to going that route. Thinking agnostically, I can still provide links to processed data sources that others can use, and provide easy-ish-to-run examples...

I’ve already seen the value of openness for my own process of getting from numbers to things-in-front-of-policymakers [frame better?]. But how to deepen the collaboration part?

The ‘shared ground truth’ thing has a couple of elements. I’ve heard more than once about data ‘black boxes’ that can result from some commissioned work. You get an analysis, but no access to the data and no way to really know how conclusions have been reached. It’s a one-time hit - once the commission’s done, you decide to either take the results on face value or not, and then have to re-commission if more is needed later. [ties to point above about this not being a purely client rel - about that ‘shared truth’ thing between us where data is one facet… oh I do say this below!]

Again — I’m not saying that can’t be valuable and necessary, as organisations can supply expert analyses that often can’t be done in-house. I also carry out that kind of interpretation. 




Build on open data, make the tools, build the capacity, link people together, do it questioningly, allow ways to get to the root and feed that back into the policy cycle, “walk asking”.

There are reasons why data work can’t be done openly (datasets that contain private information) or won’t be done openly (data/methods are IP a firm earns its living from; researchers protecting a lovingly curated dataset). But in regional policy, and with the vast body of data the ONS among others hold, there’s plenty of scope for it.

This is in GVA post and should connect:

And then something on: why the orig data sources are not enough. Just supplying openly isn’t enough. Without capacity to see what’s in that data, you’re still blind. What exactly does that capacity look like and how do we build it?


More recently, I’ve been re-using these tools to help other Yorkshire government bodies get insights quickly. This came about quite serendipitously, but it’s helped convince me it’s a good way to work. [Explain something about how much it speeds things up / how cost effective it is]

(This is all on my github where I’m trying to corral more of it into the regionalecontools site, itself a github repo; the website’s all generated using R.) 

I’m not suggesting how I’ve approached this is anything like the best way - but I am arguing that building these pipelines openly leads to good things that otherwise couldn’t happen. What I’d love to see is what others can do, and what kind of tools we could build together. 

I will now proceed to go on about this at length, starting with a mildly trite statement that I’ll then unpick. 

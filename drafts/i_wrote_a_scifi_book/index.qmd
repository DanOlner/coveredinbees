---
title: "I wrote a sci-fi book about AI before chatGPT came out. Now what?"
date: "2025-09-25"
categories: [fiction, scifi]
---

![](verytiredofAI.png)

I wrote a sci-fi book. I started the research for it in 2018, from an idea I’d had in 2012. I had a first draft by mid 2021. After no luck pitching to agents, I disassembled that draft and put it back together by the following summer in 2022, and then churned it through another round of agent pitches (also nope).

A few months later, at the end of 2022, openAI [released](https://www.searchenginejournal.com/history-of-chatgpt-timeline/488370/) chatGPT 3.5 for public use. 






It saw the [most rapid tech adoption](https://benjamintodd.substack.com/p/when-people-say-ai-isnt-finding-real) ever. As I write in 2025, space-race levels of nation-state competition are underway to gain AI dominance. It’s being inserted into our daily lives whether we ask for it or no. The hype is... well, it’s stratospheric. Bumping into satellites. Past the moon.






Things to say next
I want closure on the book. I’m going to do an indiegogo campaign leading up to self-publishing.
I’m going to attempt one last re-draft, and here on the blog I’ll talk about how our pre- and post- LLM world has (a) changed how I think about the book and (b) changed how I think about AI, and its impact on us. I will absolutely, definitely be shoehorning that into my economic geography wafflings.

Somehow it’s now the summer of 2025. I want closure on this. It was always obviously a not particularly commercial proportion (you learn how absolutely indispensable that is as you dig into traditional publishing).

Via design your life 2022: “I built a scifi world, and a really fucking intense one. The book is great”. Woo! This is very unlike me, so worth pointing that out!
Like running through the streets wearing nothing but a fez and a feather boa: equally mortifying and liberating.


Anyone who knows me knows I struggle to see the value of my own work, so I find myself in a highly unusual situation with this book - I think it's really good. I'm super-proud of it. This *never* happens.

So while I failed to persuade anyone it was commercial enough for traditional publishing, I feel baffingly, [DunningKrugerly](https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect) confident that a certain kind of sci-fi fan will dig it. 

It's not without its flaws, some of which are far too baked in... but.

Like running through the streets wearing nothing but a fez and a feather boa: equally mortifying and liberating.

“How I’d change this scene / why I might just leave alone” is worth writing up.




It’s not a good idea to allow current events to blow one’s ideas around like a weathervane – the book has to remain a product of its pre-chatGPT time. But coming back to it now, equidistant on the other side, does offer a chance to reflect on everything that’s happened. If I can just strike a good balance between disassembling the whole thing and insisting nothing needs to change...




One of the central things the book explores is how deeply artificial intelligence could get tangled in human language use. 

The central idea – that AI’s impact would be felt especially strongly in our relationship with language – obviously still has legs. And we’re equally clearly only in the foothills of those changes now.




There’s no way around how fascinated we are by the idea of AI as ‘other mind’ and the questions that raises, all while several actual AI researchers beg us to please stop talking about it (not the ones trying to raise capital by fuelling the AGI bandwagon). 

Other issue: there’s just so much analysis and discussion of AI now! How to stand out against that noise? Is it possible to be interesting? E.g. https://bsky.app/profile/sarahkendzior.bsky.social/post/3lo7srsyvoc27





I'm going to try and make these posts of interest to two to three types of reader:

1. You're interested in the nuts and bolts of fiction writing and self-publishing (including things like using Scrivener) and want to follow my journey as I get this thing out into the world.
2. You're into the political economy of technological change. You may be trying to get under the skin of what's actually happening with AI, but I'm probably going to argue - despite the book's themes - that we shouldn't understand it as a radical break. But that'll all be up for grabs.

(Do a much shorter version of those two, don't be so over the top about it!)

That'll include “How I’d change this scene / why I might just leave alone” is worth writing up. I doubt I'll be going through every chapter one by one like this, but there's some it'll be fun to unpick here.

Probably very spoilery, on the offchance anyone wants there to still be surprises in the final book.

AI is regularly the [MacGuffin](https://tvtropes.org/pmwiki/pmwiki.php/Main/MacGuffin) in movies ([latest example](https://www.reddit.com/r/Mission_Impossible/comments/14bw6s2/what_is_the_macguffin_in_dead_reckoning/)) but it’s also become a policy and economy MacGuffin. “How to improve productivity? AI. How to make public services better? AI. How can I stop my male pattern balding? AI.” Etc. Every second article on LinkedIn is now either “AI must be resisted / resistance is futile” (see [Ursula von der Leyen](https://www.linkedin.com/feed/update/urn:li:activity:7381720419516452864/) for example of the latter).

One suspects many may be mistaking AI for magic fairy dust.





It’s tricky to chart a sane course through all this. 

Compare to Coyle’s point about BIP and AIP (before and after the iphone). Quote:
Coyle quote on smartphone world

I had a few things I wanted to try and do. Artificial Intelligence and sci-fi are obviously joined at the hip; the two have grown together, feeding off each other. The common instinct has been to push it to its extremes: AI living among us has almost always been either heaven, liberating humans from all Earthly drudgery, or a glowing-red-eyed hell where the best humans can hope for is that AI wants us as pets.

But it won’t happen that way. Or more accurately, it hasn’t and isn’t happening that way, and it will continue to very not happen. It’ll be as it’s always been – an almost entirely unpredictable mess. People and our technology have always grown together, changing each other in tandem. 

Speculative fiction has to speculate, but it doesn’t need to be trying to forecast. The speculation has other purposes.
Fiction has to try and predict, it can’t avoid it – but it’s the mess that interests me, not the extremes.

As Le Guin has said, science fiction isn’t about prediction… no, she said something better than this! Err what was it?
https://www.goodreads.com/topic/show/1294820-introduction-left-hand-of-darkness

> "Prediction is the business of prophets, clairvoyants, and futurologists. It is not the business of novelists. A novelist's business is lying. The weather bureau will tell you what next Tuesday will be like, and the Rand Corporation will tell you what the twenty-first century will be like. I don't recommend that you turn to the writers of fiction for such information. It's none of their business."

Cf. actually working onwhere this goes.


I started with two seeds and let them grow together, to see what mess emerged.

If neuro knowledge is a vast, carefully curated palace full of the most delicate paintings (see e.g. Damasio’s Self Comes to Mind, a book I leaned on heavily for brain ideas), then I broke into that palace in the dead of night with a swagbag, cut as many pictures out of frames with a stanley knife as I could and scarpered before the cops arrived.

Start from the premise that there’s nothing in principle stopping a genuinely artificial intelligence being created. After all, we know intelligence can arise from matter – so it’s just about how the matter is arranged, right? (I am rejecting any ghosts in the machine... well almost all of them. There might be room for a sort of fudged mystical notion of consciousness, but probably not).

Cf. https://www.psychologytoday.com/gb/blog/the-digital-self/202504/fossilized-cognition-and-the-strange-intelligence-of-ai

What I wanted to try and do with all those stanley knife’d ideas: convey just how intractably difficult it would be a re-create something as complex as a human mind.

Part of the issue there: what exactly is it we’d be trying to recreate? What’s the fascination here? (That we see in sci-fi all the time – the compelling, uncanny-almost-human...)

Vs what it takes to make a person accept something as an emotional connection? That’s absolutely a side issue I raise quickly and move on, because it’s obvious enough to see everywhere – humans have emotional connections to non-humans all the time; there’s a kind of emotional turing test that bears no relation to “actually on a par with human” intelligence [care home example; black mirror’s various dolls]

Point: the idea of a ‘singularity’ is beside the point, largely. We already have super intelligence – actually, Zuck put this well [fridman interview].

The sense here is: the moment superhuman intelligence arrives, it’ll start a feedback loop that will quickly leave us far behind, cognitive insects to its vast, god like eye.

Two things: (1) if that were true, it would already have happened in the systems we’ve built that use humans as their components. Or – that kind of collective intelligence falsifies the feedback idea, or puts a cap on its expansion. (2) Actually, it did happen. This is Hayek’s point: humans created superintelligence, but we usually fail to see it, and so believe we can tinker with the machinery, not understanding – again – that we are mere ants (the insect parallel works on so many levels here...)

i.e. no single human could create a 747 or an iphone or Canterbury (which I pick because same number of people as 747) even if given infinite time. Equally, no group of humans could if they were dropped into an isolated desert alone, even with an instruction manual: our collective intelligence is made of material and history, it's a living fabric we carry.

[This is a good point I should dig into more. Intelligence isn't free floating, it's veeeery tangled.]

But might be that collective human intelligence is just a very limited “aura”, an intimation of something smarter than individuals, but still highly limited in its bounds?

Compare to a Turing or a Von Neuman. The idea that once AI bypasses… and then we get to several superintelligence tropes: star trek’s awkward guy / moriarty / flowers for algenon / that short story by Ted Chiang – the Infallible, the God. The perfect manipulator behind the scenes, controlling everything (Westworld, Deus Ex) [Oh I could do with playing with that trope, having IPAI make clear it really doesn’t...]

[in book world, all these tropes need to be owned by someone...]

Which presents a bit of a problem for the fiction writer – given we’re not superintelligent, how to write a superintelligence? Iain Banks’ approach was maybe sensible – the vastest multidimensional Minds, one escapes in his first book, and the only thing we ever hear it say is, “Uh oh.”

So don't try, and that's OK. Back to Le Guin's point - these are thought experiments. Shelley didn't need to be a superstrong monster to write about one. [Not sure that parallel works! Easier to imagine smashing through a wall than solving protein folding?]

And THAT then feeds back into the politics very quickly. “Not power of AI but what power will do with AI.”

Cf. Hayek’s bastards too – the point has never been the theory, it’s been the cover for telling the rest of us to pipe down, accept it, accept having the social justice educated out of us for the benefit of the superintelligent system we live in.

but they don’t understand collective intelligence because they deny the possibility of understanding it and worship it instead, assuming it’s like some kind of spirit that can be summoned by destroying organised systems – see e.g. what Twitter turned into, contrast with wikipedia. But note how they also justify this with a particular take on “truth”… cf. https://en.wikipedia.org/wiki/Dark_Enlightenment

Oh god and then there’s “truth”. Cf. https://bsky.app/profile/wolvendamien.bsky.social/post/3louunglyts2u

LLM success shows – truth is somewhat of a side issue to productivity, words-as-output.

And that overlaps with tyrannical AI futures, which again want to avoid. Cf. https://en.wikipedia.org/wiki/Dark_Enlightenment

And the excellent chinese short story that has a perfect take on a very similar AI tech to the one I use in mine – but goes to the authoritarian extreme of all words slowly being banned. [Note 1984 does that - number of words shrinking over time.]






That all the various “new theory explains consciousness by e.g. finding another distributed mechanism that might underpin binding” miss the point entirely; there’s a thing at the core of it that we can only talk about through the spaces left after we’ve cut away what can rationally be discussed. Cf. Via Nick text recently: "Developing an ODTBT-based consciousness model grounded in oscillatory physics, any researchers working on similar frameworks open to dialogue?"

What’s the relationship between ‘authentic’ creativity and the tools we use? Contrast with Bowie style randomisation etc, or any other tool we’ve used throughout history. Goes right back to 2002 asking what diff ICT makes with “organic utopians”.

What’s false about trying to divide into “genuine human article / false flag machine produced”? (Obviously much harder now; now use short story to try and talk about that…) Though that’s the way it’s going. (The Writers’ Room scene needs to deal with that.)




It wouldn't be up to much if its longevity wasn't much longer than two years.

I'm just reading two 'computer runs everything' sci-fi books from quite opposite timepoints: Arthur C Clark's City and the Stars, and [that tree one]



Punchlines??

Actually, turned out to be accidentally good training for the period we currently find ourselves in. Handy.

So yeah, I did have a go at making a ripping yarn based on copyright and intellectual property law. I’ll let you judge the success of that, but I personally had a wild time.

A period where AI has move from ... to centre stage of every single discussion, with daily news headlines and opinions, every other linkedin post about how it’ll transform work, usually a seminar titled something like “Will AI allow us to live like Wallace and Gromit / will AI keep everyone’s sock drawers organised” etc.

A lot people now would likely happily pay money if companies stopped shoving “AI” in our products and if it would make everyone stop using the phrase online.

There’s no way around how fascinated we are by the idea of AI as ‘other mind’, maybe 'alien mind' and the questions that raises, all while several actual AI researchers beg us to please stop talking about it like that (not the ones trying to raise capital by fuelling the AGI bandwagon). 


# Other topics

## Learning

https://bsky.app/profile/alexvont.bsky.social/post/3lolgkvlsis2q – on the NY Mag piece and what’s happening to academia, the universal-acid nature of it. I do need to rethink a bit (while really just bolting on…)

Luckily, enough of the book was already going along these grains, it’s not as hard as it might have been.

Archived version of the full article if needed: https://bsky.app/profile/hypervisible.bsky.social/post/3lolmr4rdok2e

And me commenting on that - maybe it'll alter cognitive costs in weird ways. https://bsky.app/profile/danolner.bsky.social/post/3lonucyhzu222

More in "other links" - check!





## CUTTINZ

> "Fortunately, though extrapolation is an element in science fiction, it isn't the name of the game by any means. It is far too rationalist and simplistic to satisfy the imaginative mind, whether the writer's or the reader's. Variables are the spice of life."

> "This book is not extrapolative. If you like you can read it, and a lot of other science fiction, as a thought-experiment. Let's say (says Mary Shelley) that a young doctor creates a human being in his laboratory; let's say (says Philip K. Dick) that the Allies lost the second world war; let's say this or that is such and so, and see what happens..."
